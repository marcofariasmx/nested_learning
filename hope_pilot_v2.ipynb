{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOPE Pilot v2 - Scalable Dataset Training\n",
    "\n",
    "This notebook trains the **HOPE Pilot model (200M parameters)** with **flexible dataset sizes**.\n",
    "\n",
    "**New in v2:**\n",
    "- ğŸ“Š **Dataset size presets**: Debug, Quick, Standard, Chinchilla-Optimal, Large\n",
    "- ğŸ§  **Smart memory management**: Auto RAM vs memory-mapped files\n",
    "- ğŸ“ˆ **Scaling guidance**: Shows trade-offs for each preset\n",
    "- ğŸ’¾ **Efficient loading**: Handles datasets from 1M to 50B+ tokens\n",
    "\n",
    "**Dataset Presets:**\n",
    "- **Debug** (1M tokens): ~1 min download - Test pipeline\n",
    "- **Quick** (50M tokens): ~10 min download - Quick experiments  \n",
    "- **Standard** (500M tokens): ~2 hours download - Decent results\n",
    "- **Chinchilla** (3.1B tokens): ~1 day download - Optimal for 155M model\n",
    "- **Large** (10B tokens): ~3 days download - High quality\n",
    "- **Custom**: Specify your own token count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch numpy einops tqdm sentencepiece omegaconf matplotlib datasets huggingface-hub langdetect ipywidgets zstandard psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENVIRONMENT: Local\n",
      "================================================================================\n",
      "âœ“ Running locally in: /Users/marcofarias/PycharmProjects/nested_learning_neural_networks/nested_learning\n",
      "ğŸ“ Directories:\n",
      "  Checkpoints: /Users/marcofarias/PycharmProjects/nested_learning_neural_networks/nested_learning/hope_pilot_v2_data/checkpoints\n",
      "  Data: /Users/marcofarias/PycharmProjects/nested_learning_neural_networks/nested_learning/hope_pilot_v2_data/data\n",
      "  Tokenizer: /Users/marcofarias/PycharmProjects/nested_learning_neural_networks/nested_learning/hope_pilot_v2_data/tokenizer\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Detect environment: Google Colab vs Local\n",
    "import os\n",
    "import glob\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"ENVIRONMENT: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Setup directories based on environment\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    DRIVE_ROOT = '/content/drive/MyDrive/hope_pilot_v2'\n",
    "    CHECKPOINT_DIR = f'{DRIVE_ROOT}/checkpoints'\n",
    "    DATA_DIR = f'{DRIVE_ROOT}/data'\n",
    "    TOKENIZER_DIR = f'{DRIVE_ROOT}/tokenizer'\n",
    "    \n",
    "    print(\"âœ“ Google Drive mounted successfully!\")\n",
    "else:\n",
    "    import pathlib\n",
    "    notebook_dir = pathlib.Path.cwd()\n",
    "    \n",
    "    DRIVE_ROOT = notebook_dir / 'hope_pilot_v2_data'\n",
    "    CHECKPOINT_DIR = str(DRIVE_ROOT / 'checkpoints')\n",
    "    DATA_DIR = str(DRIVE_ROOT / 'data')\n",
    "    TOKENIZER_DIR = str(DRIVE_ROOT / 'tokenizer')\n",
    "    \n",
    "    print(f\"âœ“ Running locally in: {notebook_dir}\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(TOKENIZER_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ“ Directories:\")\n",
    "print(f\"  Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"  Data: {DATA_DIR}\")\n",
    "print(f\"  Tokenizer: {TOKENIZER_DIR}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports and Device Configuration\n",
    "\n",
    "Load all required libraries and detect available compute device (CUDA, MPS, or CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps (MPS (Metal Performance Shaders))\n",
      "GPU: Apple Silicon GPU\n",
      "Unified Memory: 34.4 GB total\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional\n",
    "import json\n",
    "from collections import Counter\n",
    "import glob\n",
    "import multiprocessing\n",
    "import psutil\n",
    "\n",
    "# FIX for \"Broken pipe\" error on macOS\n",
    "if __name__ != '__main__':\n",
    "    try:\n",
    "        multiprocessing.set_start_method('fork', force=True)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "\n",
    "# Fix fsspec zstd compression support for SlimPajama dataset\n",
    "import fsspec.utils\n",
    "try:\n",
    "    import zstandard\n",
    "    if 'zst' not in fsspec.utils.compressions:\n",
    "        fsspec.utils.compressions['zst'] = 'zstd'\n",
    "        fsspec.utils.compressions['zstd'] = 'zstd'\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Check for GPU availability (CUDA, MPS, or CPU)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    device_type = \"CUDA GPU\"\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    device_name = \"Apple Silicon GPU\"\n",
    "    device_type = \"MPS (Metal Performance Shaders)\"\n",
    "    total_memory = None\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    device_name = \"CPU\"\n",
    "    device_type = \"CPU\"\n",
    "    total_memory = None\n",
    "\n",
    "print(f\"Using device: {device} ({device_type})\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {device_name}\")\n",
    "    print(f\"GPU Memory: {total_memory:.2f} GB\")\n",
    "elif device.type == 'mps':\n",
    "    print(f\"GPU: {device_name}\")\n",
    "    mem = psutil.virtual_memory()\n",
    "    print(f\"Unified Memory: {mem.total / 1e9:.1f} GB total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Size Configuration\n",
    "\n",
    "Choose your dataset size based on your goals and resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Configuration\n",
    "\n",
    "Configure training steps and model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Memory tracking utilities loaded\n"
     ]
    }
   ],
   "source": [
    "# GPU Memory Tracking Utilities\n",
    "def print_gpu_memory(stage_name: str = \"\"):\n",
    "    \"\"\"Print current GPU memory usage (CUDA has full tracking, MPS has limited)\"\"\"\n",
    "    if torch.cuda.is_available() and device.type == 'cuda':\n",
    "        allocated = torch.cuda.memory_allocated() / (1024**3)  # GB\n",
    "        reserved = torch.cuda.memory_reserved() / (1024**3)    # GB\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "        free = total - reserved\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"GPU MEMORY: {stage_name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"ğŸ“Š Allocated (actual usage):  {allocated:6.2f} GB / {total:.2f} GB ({allocated/total*100:5.1f}%)\")\n",
    "        print(f\"ğŸ“¦ Reserved (by PyTorch):     {reserved:6.2f} GB / {total:.2f} GB ({reserved/total*100:5.1f}%)\")\n",
    "        print(f\"ğŸ’š Free (available):          {free:6.2f} GB / {total:.2f} GB ({free/total*100:5.1f}%)\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        return {\n",
    "            'allocated_gb': allocated,\n",
    "            'reserved_gb': reserved,\n",
    "            'free_gb': free,\n",
    "            'total_gb': total\n",
    "        }\n",
    "    elif device.type == 'mps':\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"GPU MEMORY: {stage_name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Try PyTorch 2.0+ MPS memory APIs (limited but better than nothing)\n",
    "        if hasattr(torch.mps, 'current_allocated_memory'):\n",
    "            allocated = torch.mps.current_allocated_memory() / (1024**3)\n",
    "            print(f\"ğŸ MPS Allocated: {allocated:.2f} GB\")\n",
    "            \n",
    "            if hasattr(torch.mps, 'driver_allocated_memory'):\n",
    "                driver = torch.mps.driver_allocated_memory() / (1024**3)\n",
    "                print(f\"ğŸ”§ Metal Driver:  {driver:.2f} GB\")\n",
    "        else:\n",
    "            print(f\"ğŸ MPS - Direct memory tracking not available (requires PyTorch 2.0+)\")\n",
    "        \n",
    "        # Show system memory as proxy (unified memory architecture)\n",
    "        try:\n",
    "            mem = psutil.virtual_memory()\n",
    "            print(f\"ğŸ’¾ Unified Memory: {mem.used / (1024**3):.2f} GB / {mem.total / (1024**3):.2f} GB\")\n",
    "            print(f\"ğŸ“Š Available: {mem.available / (1024**3):.2f} GB ({100 - mem.percent:.1f}%)\")\n",
    "        except ImportError:\n",
    "            pass\n",
    "        \n",
    "        print(f\"ğŸ’¡ For detailed GPU tracking: pip install asitop && sudo asitop\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        return None\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  No GPU available for {stage_name}\")\n",
    "        return None\n",
    "\n",
    "# Clear any cached memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "elif torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n",
    "\n",
    "print(\"âœ“ Memory tracking utilities loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "DATASET PRESET: CHINCHILLA\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ“Š Chinchilla-optimal for 155M params (20 tokens/param)\n",
      "ğŸ¯ Target tokens: 3,100,000,000 (3.10B)\n",
      "ğŸ“ˆ Quality: â­â­â­â­ (Excellent)\n",
      "ğŸ’¡ Use case: Optimal training, paper-quality results\n",
      "â±ï¸  Download time: ~1.0 days\n",
      "ğŸ’¾ Disk space: ~25.0 GB\n",
      "\n",
      "ğŸ“ Model size: 155,000,000 parameters (155M)\n",
      "ğŸ¯ Chinchilla ratio: 20.0 tokens/param\n",
      "   âœ… Good range for this model size\n",
      "\n",
      "ğŸ’¡ To change preset, edit DATA_PRESET above\n",
      "   Options: 'debug', 'quick', 'standard', 'chinchilla', 'large', 'custom'\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# DATASET SIZE PRESET SELECTION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "DATA_PRESET = \"chinchilla\"  # Options: \"debug\", \"quick\", \"standard\", \"chinchilla\", \"large\", \"custom\"\n",
    "\n",
    "# Preset configurations\n",
    "DATA_PRESETS = {\n",
    "    \"debug\": {\n",
    "        \"target_tokens\": 1_000_000,  # 1M tokens\n",
    "        \"doc_multiplier\": 0.1,\n",
    "        \"download_time_min\": 1,\n",
    "        \"disk_space_gb\": 0.01,\n",
    "        \"description\": \"Tiny dataset for testing pipeline\",\n",
    "        \"quality\": \"â­ (Poor - just for testing)\",\n",
    "        \"use_case\": \"Debug code, test setup\"\n",
    "    },\n",
    "    \"quick\": {\n",
    "        \"target_tokens\": 50_000_000,  # 50M tokens\n",
    "        \"doc_multiplier\": 5,\n",
    "        \"download_time_min\": 10,\n",
    "        \"disk_space_gb\": 0.5,\n",
    "        \"description\": \"Small dataset for quick experiments\",\n",
    "        \"quality\": \"â­â­ (Basic)\",\n",
    "        \"use_case\": \"Quick experiments, prototyping\"\n",
    "    },\n",
    "    \"standard\": {\n",
    "        \"target_tokens\": 500_000_000,  # 500M tokens\n",
    "        \"doc_multiplier\": 50,\n",
    "        \"download_time_min\": 120,\n",
    "        \"disk_space_gb\": 5,\n",
    "        \"description\": \"Medium dataset for decent results\",\n",
    "        \"quality\": \"â­â­â­ (Good)\",\n",
    "        \"use_case\": \"Research, decent training runs\"\n",
    "    },\n",
    "    \"chinchilla\": {\n",
    "        \"target_tokens\": 3_100_000_000,  # 3.1B tokens (20x 155M params)\n",
    "        \"doc_multiplier\": 310,\n",
    "        \"download_time_min\": 1440,  # ~1 day\n",
    "        \"disk_space_gb\": 25,\n",
    "        \"description\": \"Chinchilla-optimal for 155M params (20 tokens/param)\",\n",
    "        \"quality\": \"â­â­â­â­ (Excellent)\",\n",
    "        \"use_case\": \"Optimal training, paper-quality results\"\n",
    "    },\n",
    "    \"large\": {\n",
    "        \"target_tokens\": 10_000_000_000,  # 10B tokens\n",
    "        \"doc_multiplier\": 1000,\n",
    "        \"download_time_min\": 4320,  # ~3 days\n",
    "        \"disk_space_gb\": 80,\n",
    "        \"description\": \"Large dataset for high quality\",\n",
    "        \"quality\": \"â­â­â­â­â­ (Exceptional)\",\n",
    "        \"use_case\": \"Production-quality, state-of-art\"\n",
    "    },\n",
    "    \"custom\": {\n",
    "        \"target_tokens\": 1_000_000_000,  # 1B tokens (modify this!)\n",
    "        \"doc_multiplier\": 100,\n",
    "        \"download_time_min\": None,\n",
    "        \"disk_space_gb\": None,\n",
    "        \"description\": \"Custom size - edit target_tokens above\",\n",
    "        \"quality\": \"Custom\",\n",
    "        \"use_case\": \"Your specific needs\"\n",
    "    }\n",
    "}\n",
    "\n",
    "data_config = DATA_PRESETS[DATA_PRESET]\n",
    "\n",
    "print(\"â•\" * 80)\n",
    "print(f\"DATASET PRESET: {DATA_PRESET.upper()}\")\n",
    "print(\"â•\" * 80)\n",
    "print(f\"ğŸ“Š {data_config['description']}\")\n",
    "print(f\"ğŸ¯ Target tokens: {data_config['target_tokens']:,} ({data_config['target_tokens']/1e9:.2f}B)\")\n",
    "print(f\"ğŸ“ˆ Quality: {data_config['quality']}\")\n",
    "print(f\"ğŸ’¡ Use case: {data_config['use_case']}\")\n",
    "if data_config['download_time_min']:\n",
    "    hours = data_config['download_time_min'] / 60\n",
    "    if hours < 1:\n",
    "        print(f\"â±ï¸  Download time: ~{data_config['download_time_min']} minutes\")\n",
    "    elif hours < 24:\n",
    "        print(f\"â±ï¸  Download time: ~{hours:.1f} hours\")\n",
    "    else:\n",
    "        print(f\"â±ï¸  Download time: ~{hours/24:.1f} days\")\n",
    "if data_config['disk_space_gb']:\n",
    "    print(f\"ğŸ’¾ Disk space: ~{data_config['disk_space_gb']:.1f} GB\")\n",
    "\n",
    "# Calculate optimal training steps for this dataset\n",
    "model_params = 155_000_000  # Your model size\n",
    "optimal_steps_chinchilla = data_config['target_tokens'] // 512  # Assuming seq_len=512\n",
    "print(f\"\\nğŸ“ Model size: {model_params:,} parameters ({model_params/1e6:.0f}M)\")\n",
    "print(f\"ğŸ¯ Chinchilla ratio: {data_config['target_tokens']/model_params:.1f} tokens/param\")\n",
    "if data_config['target_tokens'] < model_params * 20:\n",
    "    print(f\"   âš ï¸  Below optimal (20 tokens/param) - may underfit\")\n",
    "elif data_config['target_tokens'] > model_params * 100:\n",
    "    print(f\"   â„¹ï¸  Above optimal - diminishing returns after {model_params*20:,} tokens\")\n",
    "else:\n",
    "    print(f\"   âœ… Good range for this model size\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ To change preset, edit DATA_PRESET above\")\n",
    "print(f\"   Options: 'debug', 'quick', 'standard', 'chinchilla', 'large', 'custom'\")\n",
    "print(\"â•\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Configuration\n",
    "\n",
    "Configure the HOPE Pilot model architecture (155M parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ¯ TRAINING CONFIGURATION\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "Batch Size:      2\n",
      "Sequence Length: 2,048\n",
      "Total Steps:     740,001\n",
      "\n",
      "Tokens/Step:     4,096\n",
      "Total Tokens:    3,031,044,096 (3.03B)\n",
      "\n",
      "Learning Rates:\n",
      "  TITAN: 0.0006\n",
      "  CMS:   0.0003\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ğŸ’¡ To change settings, edit the values at the top of this cell!\n",
      "   All other cells will automatically use these values.\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¯ MASTER CONFIGURATION - CHANGE SETTINGS HERE!\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# This is the ONLY place you need to edit to change training parameters.\n",
    "# All other cells will automatically use these values.\n",
    "\n",
    "# TRAINING CONFIGURATION (Optimized for 32GB Mac with MPS)\n",
    "BATCH_SIZE = 2              # Reduced for Option 2 memory requirements\n",
    "SEQ_LEN = 2048              # Context window length (2048 = matches official spec)\n",
    "TOTAL_STEPS = 740001        # Adjusted to maintain same total tokens (2 * 2048 * 740,001 = 3.03B)\n",
    "SAVE_INTERVAL = 1000        # Save checkpoint every N steps\n",
    "\n",
    "# LEARNING RATES (Official spec from GitHub repo)\n",
    "TITAN_LR = 6.0e-4           # TITAN level learning rate\n",
    "CMS_LR = 3.0e-4             # CMS levels learning rate\n",
    "\n",
    "# CALCULATED VALUES (Don't change these - auto-calculated)\n",
    "TOKENS_PER_STEP = BATCH_SIZE * SEQ_LEN\n",
    "TOTAL_TOKENS = TOTAL_STEPS * TOKENS_PER_STEP\n",
    "TOTAL_TOKENS_B = TOTAL_TOKENS / 1e9\n",
    "\n",
    "print(\"â•\" * 80)\n",
    "print(\"ğŸ¯ TRAINING CONFIGURATION\")\n",
    "print(\"â•\" * 80)\n",
    "print(f\"Batch Size:      {BATCH_SIZE}\")\n",
    "print(f\"Sequence Length: {SEQ_LEN:,}\")\n",
    "print(f\"Total Steps:     {TOTAL_STEPS:,}\")\n",
    "print(f\"\")\n",
    "print(f\"Tokens/Step:     {TOKENS_PER_STEP:,}\")\n",
    "print(f\"Total Tokens:    {TOTAL_TOKENS:,} ({TOTAL_TOKENS_B:.2f}B)\")\n",
    "print(f\"\")\n",
    "print(f\"Learning Rates:\")\n",
    "print(f\"  TITAN: {TITAN_LR}\")\n",
    "print(f\"  CMS:   {CMS_LR}\")\n",
    "print(\"â•\" * 80)\n",
    "print()\n",
    "print(\"ğŸ’¡ To change settings, edit the values at the top of this cell!\")\n",
    "print(\"   All other cells will automatically use these values.\")\n",
    "print(\"â•\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "PILOT MODEL CONFIGURATION\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ğŸ“ Architecture:\n",
      "  â€¢ Vocabulary size: 32,000\n",
      "  â€¢ Model dimension: 512\n",
      "  â€¢ Transformer layers: 12\n",
      "  â€¢ Attention heads: 8\n",
      "  â€¢ Sequence length: 2048\n",
      "  â€¢ Total parameters: ~54.2M\n",
      "\n",
      "ğŸ¯ Training:\n",
      "  â€¢ Batch size: 2 (optimized for memory bandwidth)\n",
      "  â€¢ Total steps: 740,001\n",
      "  â€¢ Tokens per step: 4,096\n",
      "  â€¢ Total tokens seen: 3,031,044,096 (3.03B)\n",
      "  â€¢ Checkpoint interval: 1,000 steps\n",
      "\n",
      "ğŸ”„ Multi-timescale Learning:\n",
      "  â€¢ TITAN period: 8 steps (slow, global patterns)\n",
      "  â€¢ CMS Fast: 1 steps (immediate feedback)\n",
      "  â€¢ CMS Mid: 4 steps (short-term patterns)\n",
      "  â€¢ CMS Slow: 32 steps (medium-term patterns)\n",
      "  â€¢ CMS Ultra: 128 steps (long-term patterns)\n",
      "\n",
      "âš¡ Mixed Precision:\n",
      "  â€¢ Enabled: fp32 (automatic mixed precision)\n",
      "  â€¢ GPU: MPS with automatic AMP\n",
      "\n",
      "ğŸ’¾ Dataset vs Model:\n",
      "  â€¢ Dataset size: 3,100,000,000 tokens\n",
      "  â€¢ Tokens in training: 3,031,044,096 tokens\n",
      "  â€¢ Dataset coverage: 0.98x\n",
      "    â„¹ï¸  Will see 97.8% of dataset (< 1 epoch)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PILOT MODEL CONFIGURATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "@dataclass\n",
    "class PilotConfig:\n",
    "    \"\"\"HOPE Pilot model configuration (155M parameters)\"\"\"\n",
    "    \n",
    "    # Architecture\n",
    "    vocab_size: int = 32000          # SentencePiece vocab size\n",
    "    dim: int = 512                   # Model dimension\n",
    "    num_layers: int = 12             # Number of transformer layers\n",
    "    heads: int = 8                   # Number of attention heads\n",
    "    seq_len: int = SEQ_LEN               # From master config above\n",
    "    \n",
    "    # Training\n",
    "    batch_size: int = BATCH_SIZE         # From master config above\n",
    "    total_steps: int = TOTAL_STEPS       # From master config above\n",
    "    save_interval: int = SAVE_INTERVAL   # From master config above\n",
    "    \n",
    "    # Learning rates\n",
    "    titan_lr: float = TITAN_LR           # From master config above\n",
    "    cms_lr: float = CMS_LR               # From master config above\n",
    "    \n",
    "    # Nested learning parameters\n",
    "    teach_scale: float = 0.10        # Teaching signal scale\n",
    "    teach_clip: float = 5.0          # Gradient clipping for teach signals\n",
    "    surprise_threshold: float = 0.02 # Threshold for surprise-based learning\n",
    "    self_mod_lr: float = 0.001       # Self-modulation learning rate\n",
    "    \n",
    "    # Multi-timescale update periods\n",
    "    titan_period: int = 8            # TITAN updates every 8 steps\n",
    "    cms_fast_period: int = 1         # Fast CMS updates every step\n",
    "    cms_mid_period: int = 4          # Mid CMS updates every 4 steps\n",
    "    cms_slow_period: int = 32        # Slow CMS updates every 32 steps\n",
    "    cms_ultra_period: int = 128      # Ultra-slow CMS updates every 128 steps\n",
    "    \n",
    "    # Teaching signal schedule\n",
    "    teach_warmup_steps: int = 2000\n",
    "    teach_decay_start: int = 120000\n",
    "    teach_decay_duration: int = 20000\n",
    "    \n",
    "    # Mixed precision (automatic based on device)\n",
    "    use_amp: bool = device.type in ['cuda', 'mps']\n",
    "    dtype: str = 'bf16' if device.type == 'cuda' else 'fp32'\n",
    "\n",
    "# Create config instance\n",
    "config = PilotConfig()\n",
    "\n",
    "# Print model summary\n",
    "print(\"â•\" * 80)\n",
    "print(\"PILOT MODEL CONFIGURATION\")\n",
    "print(\"â•\" * 80)\n",
    "print(f\"\\nğŸ“ Architecture:\")\n",
    "print(f\"  â€¢ Vocabulary size: {config.vocab_size:,}\")\n",
    "print(f\"  â€¢ Model dimension: {config.dim}\")\n",
    "print(f\"  â€¢ Transformer layers: {config.num_layers}\")\n",
    "print(f\"  â€¢ Attention heads: {config.heads}\")\n",
    "print(f\"  â€¢ Sequence length: {config.seq_len}\")\n",
    "\n",
    "# Calculate parameter count\n",
    "params_per_layer = (\n",
    "    4 * config.dim * config.dim +  # Attention QKV + output projection\n",
    "    3 * config.dim +               # LayerNorm parameters\n",
    "    8 * config.dim * config.dim +  # FFN (4x expansion)\n",
    "    2 * config.dim                 # FFN LayerNorm\n",
    ")\n",
    "embedding_params = config.vocab_size * config.dim\n",
    "total_params = embedding_params + (params_per_layer * config.num_layers)\n",
    "print(f\"  â€¢ Total parameters: ~{total_params/1e6:.1f}M\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Training:\")\n",
    "print(f\"  â€¢ Batch size: {config.batch_size} (optimized for memory bandwidth)\")\n",
    "print(f\"  â€¢ Total steps: {config.total_steps:,}\")\n",
    "print(f\"  â€¢ Tokens per step: {config.batch_size * config.seq_len:,}\")\n",
    "print(f\"  â€¢ Total tokens seen: {config.total_steps * config.batch_size * config.seq_len:,} ({config.total_steps * config.batch_size * config.seq_len / 1e9:.2f}B)\")\n",
    "print(f\"  â€¢ Checkpoint interval: {config.save_interval:,} steps\")\n",
    "\n",
    "print(f\"\\nğŸ”„ Multi-timescale Learning:\")\n",
    "print(f\"  â€¢ TITAN period: {config.titan_period} steps (slow, global patterns)\")\n",
    "print(f\"  â€¢ CMS Fast: {config.cms_fast_period} steps (immediate feedback)\")\n",
    "print(f\"  â€¢ CMS Mid: {config.cms_mid_period} steps (short-term patterns)\")\n",
    "print(f\"  â€¢ CMS Slow: {config.cms_slow_period} steps (medium-term patterns)\")\n",
    "print(f\"  â€¢ CMS Ultra: {config.cms_ultra_period} steps (long-term patterns)\")\n",
    "\n",
    "print(f\"\\nâš¡ Mixed Precision:\")\n",
    "if config.use_amp:\n",
    "    print(f\"  â€¢ Enabled: {config.dtype} (automatic mixed precision)\")\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"  â€¢ GPU: CUDA with bfloat16\")\n",
    "    else:\n",
    "        print(f\"  â€¢ GPU: MPS with automatic AMP\")\n",
    "else:\n",
    "    print(f\"  â€¢ Disabled (CPU mode)\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ Dataset vs Model:\")\n",
    "tokens_seen = config.total_steps * config.batch_size * config.seq_len\n",
    "print(f\"  â€¢ Dataset size: {data_config['target_tokens']:,} tokens\")\n",
    "print(f\"  â€¢ Tokens in training: {tokens_seen:,} tokens\")\n",
    "print(f\"  â€¢ Dataset coverage: {tokens_seen / data_config['target_tokens']:.2f}x\")\n",
    "if tokens_seen < data_config['target_tokens']:\n",
    "    print(f\"    â„¹ï¸  Will see {tokens_seen / data_config['target_tokens'] * 100:.1f}% of dataset (< 1 epoch)\")\n",
    "elif tokens_seen > data_config['target_tokens'] * 3:\n",
    "    print(f\"    âš ï¸  Will see dataset {tokens_seen / data_config['target_tokens']:.1f}x (may overfit)\")\n",
    "else:\n",
    "    print(f\"    âœ… Good coverage ({tokens_seen / data_config['target_tokens']:.1f}x passes)\")\n",
    "\n",
    "print(\"â•\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Download Training Data\n",
    "\n",
    "Download text data from multiple sources (RefinedWeb, Wikipedia, C4, SlimPajama, Code).\n",
    "\n",
    "The data will be filtered, deduplicated, and saved to disk. Subsequent runs will skip this step if data already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data filtering functions loaded.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "def filter_and_save_corpus(name, dataset_name, subset, split, text_column, \n",
    "                           limit, output_path, target_lang='en', \n",
    "                           min_chars=200, max_chars=8000):\n",
    "    \"\"\"Download, filter, and save a corpus\"\"\"\n",
    "    \n",
    "    filtered_dir = f\"{DATA_DIR}/filtered\"\n",
    "    os.makedirs(filtered_dir, exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"  âœ“ [{name}] Already exists, skipping download\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n  [{name}] Downloading from {dataset_name}...\")\n",
    "    \n",
    "    # Load dataset\n",
    "    if subset:\n",
    "        ds = load_dataset(dataset_name, subset, split=split, streaming=True)\n",
    "    else:\n",
    "        ds = load_dataset(dataset_name, split=split, streaming=True)\n",
    "    \n",
    "    print(f\"  [{name}] Filtering {limit:,} documents...\")\n",
    "    filtered_docs = []\n",
    "    processed = 0\n",
    "    \n",
    "    for example in ds:\n",
    "        if len(filtered_docs) >= limit:\n",
    "            break\n",
    "        \n",
    "        processed += 1\n",
    "        if processed % 500 == 0:\n",
    "            print(f\"    Processed {processed:,}, kept {len(filtered_docs):,}/{limit:,}\", end='\\r')\n",
    "        \n",
    "        text = example.get(text_column, '')\n",
    "        \n",
    "        # Length filter\n",
    "        if len(text) < min_chars or len(text) > max_chars:\n",
    "            continue\n",
    "        \n",
    "        # Language detection\n",
    "        try:\n",
    "            if detect(text[:1000]) != target_lang:\n",
    "                continue\n",
    "        except LangDetectException:\n",
    "            continue\n",
    "        \n",
    "        filtered_docs.append(text)\n",
    "    \n",
    "    # Save to file\n",
    "    print(f\"\\n  [{name}] Saving {len(filtered_docs):,} documents...\")\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for doc in filtered_docs:\n",
    "            f.write(doc.replace('\\n', '\\\\n') + '\\n')\n",
    "    \n",
    "    print(f\"  [{name}] âœ“ Complete!\")\n",
    "\n",
    "print(\"Data filtering functions loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DOWNLOADING TRAINING DATA\n",
      "================================================================================\n",
      "Using CHINCHILLA preset - downloading 310x base amount\n",
      "Data is saved and only needs to be downloaded once.\n",
      "\n",
      "  âœ“ [RefinedWeb] Already exists, skipping download\n",
      "  âœ“ [Wikipedia] Already exists, skipping download\n",
      "  âœ“ [C4] Already exists, skipping download\n",
      "  âœ“ [SlimPajama] Already exists, skipping download\n",
      "  âœ“ [Code] Already exists, skipping download\n",
      "\n",
      "================================================================================\n",
      "âœ“ ALL CORPORA DOWNLOADED\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DOWNLOADING TRAINING DATA\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Using {DATA_PRESET.upper()} preset - downloading {data_config['doc_multiplier']}x base amount\")\n",
    "print(\"Data is saved and only needs to be downloaded once.\\n\")\n",
    "\n",
    "# Calculate scaled document counts\n",
    "base_multiplier = 10  # Base docs per corpus category\n",
    "scaled_multiplier = data_config['doc_multiplier']\n",
    "\n",
    "# Download RefinedWeb (40% of mixture)\n",
    "filter_and_save_corpus(\n",
    "    name=\"RefinedWeb\",\n",
    "    dataset_name=\"HuggingFaceFW/fineweb\",\n",
    "    subset=\"sample-10BT\",\n",
    "    split=\"train\",\n",
    "    text_column=\"text\",\n",
    "    limit=int(400 * scaled_multiplier),\n",
    "    output_path=f\"{DATA_DIR}/filtered/refinedweb_en.txt\"\n",
    ")\n",
    "\n",
    "# Download Wikipedia (20%)\n",
    "filter_and_save_corpus(\n",
    "    name=\"Wikipedia\",\n",
    "    dataset_name=\"wikimedia/wikipedia\",\n",
    "    subset=\"20231101.en\",\n",
    "    split=\"train\",\n",
    "    text_column=\"text\",\n",
    "    limit=int(200 * scaled_multiplier),\n",
    "    output_path=f\"{DATA_DIR}/filtered/wikipedia_en.txt\"\n",
    ")\n",
    "\n",
    "# Download C4 (15%)\n",
    "filter_and_save_corpus(\n",
    "    name=\"C4\",\n",
    "    dataset_name=\"allenai/c4\",\n",
    "    subset=\"en\",\n",
    "    split=\"train\",\n",
    "    text_column=\"text\",\n",
    "    limit=int(150 * scaled_multiplier),\n",
    "    output_path=f\"{DATA_DIR}/filtered/c4_en.txt\"\n",
    ")\n",
    "\n",
    "# Download SlimPajama (15%)\n",
    "filter_and_save_corpus(\n",
    "    name=\"SlimPajama\",\n",
    "    dataset_name=\"cerebras/SlimPajama-627B\",\n",
    "    subset=None,\n",
    "    split=\"train\",\n",
    "    text_column=\"text\",\n",
    "    limit=int(150 * scaled_multiplier),\n",
    "    output_path=f\"{DATA_DIR}/filtered/slimpajama_en.txt\"\n",
    ")\n",
    "\n",
    "# Download Code (10%)\n",
    "filter_and_save_corpus(\n",
    "    name=\"Code\",\n",
    "    dataset_name=\"codeparrot/codeparrot-clean-train\",\n",
    "    subset=None,\n",
    "    split=\"train\",\n",
    "    text_column=\"content\",\n",
    "    limit=int(100 * scaled_multiplier),\n",
    "    output_path=f\"{DATA_DIR}/filtered/code_en.txt\",\n",
    "    max_chars=12000\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ“ ALL CORPORA DOWNLOADED\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Tokenizer\n",
    "\n",
    "Train a SentencePiece tokenizer (32k vocab, unigram) on the downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Tokenizer already exists at: /Users/marcofarias/PycharmProjects/nested_learning_neural_networks/nested_learning/hope_pilot_v2_data/tokenizer/spm_32000_unigram.model\n",
      "\n",
      "================================================================================\n",
      "TOKENIZER LOADED\n",
      "================================================================================\n",
      "ğŸ“ Vocab size: 32,000\n",
      "ğŸ”¤ Model type: Unigram\n",
      "ğŸ“ Path: /Users/marcofarias/PycharmProjects/nested_learning_neural_networks/nested_learning/hope_pilot_v2_data/tokenizer/spm_32000_unigram.model\n",
      "\n",
      "ğŸ’¡ Test encoding:\n",
      "  Input:   'Hello, world! This is a test.'\n",
      "  Tokens:  [12136, 259, 502, 359, 370, 273, 268, 552, 262]... (9 tokens)\n",
      "  Decoded: 'Hello, world! This is a test.'\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "tokenizer_path = f\"{TOKENIZER_DIR}/spm_32000_unigram.model\"\n",
    "\n",
    "if not os.path.exists(tokenizer_path):\n",
    "    print(\"=\"*80)\n",
    "    print(\"TRAINING SENTENCEPIECE TOKENIZER\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Vocabulary size: {config.vocab_size:,}\")\n",
    "    print(f\"Model type: unigram\\n\")\n",
    "    \n",
    "    # Get all text files\n",
    "    all_text_files = sorted(glob.glob(f\"{DATA_DIR}/filtered/*.txt\"))\n",
    "    \n",
    "    # Check if files exist\n",
    "    if len(all_text_files) == 0:\n",
    "        print(\"âŒ ERROR: No training data found!\")\n",
    "        print(f\"   Expected location: {DATA_DIR}/filtered/*.txt\")\n",
    "        print(f\"\\nâš ï¸  You must run the DATA DOWNLOAD cells first (Section 6)!\")\n",
    "        print(f\"   The tokenizer needs text files to train on.\")\n",
    "        raise FileNotFoundError(f\"No text files found in {DATA_DIR}/filtered/\")\n",
    "    \n",
    "    print(f\"Training on {len(all_text_files)} corpora:\")\n",
    "    for f in all_text_files:\n",
    "        file_size = os.path.getsize(f) / (1024**2)\n",
    "        print(f\"  â€¢ {os.path.basename(f)} ({file_size:.1f} MB)\")\n",
    "    print()\n",
    "    \n",
    "    # Train tokenizer\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input=','.join(all_text_files),\n",
    "        model_prefix=f\"{TOKENIZER_DIR}/spm_32000_unigram\",\n",
    "        vocab_size=config.vocab_size,\n",
    "        model_type='unigram',\n",
    "        normalization_rule_name='nfkc',\n",
    "        remove_extra_whitespaces=True,\n",
    "        input_sentence_size=2000000,\n",
    "        shuffle_input_sentence=True,\n",
    "        character_coverage=0.9995,\n",
    "        byte_fallback=True,\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ“ Tokenizer trained and saved\")\n",
    "else:\n",
    "    print(f\"âœ“ Tokenizer already exists at: {tokenizer_path}\")\n",
    "\n",
    "# Load tokenizer\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(tokenizer_path)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TOKENIZER LOADED\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"ğŸ“ Vocab size: {sp.GetPieceSize():,}\")\n",
    "print(f\"ğŸ”¤ Model type: Unigram\")\n",
    "print(f\"ğŸ“ Path: {tokenizer_path}\")\n",
    "print(f\"\\nğŸ’¡ Test encoding:\")\n",
    "test_text = \"Hello, world! This is a test.\"\n",
    "encoded = sp.EncodeAsIds(test_text)\n",
    "decoded = sp.DecodeIds(encoded)\n",
    "print(f\"  Input:   '{test_text}'\")\n",
    "print(f\"  Tokens:  {encoded[:10]}... ({len(encoded)} tokens)\")\n",
    "print(f\"  Decoded: '{decoded}'\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Tokenize Data\n",
    "\n",
    "Convert text documents to binary token files for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TOKENIZING CORPORA\n",
      "================================================================================\n",
      "\n",
      "âš ï¸  WARNING: Token file already exists!\n",
      "ğŸ“ File: /Users/marcofarias/PycharmProjects/nested_learning_neural_networks/nested_learning/hope_pilot_v2_data/data/combined_tokens.bin\n",
      "ğŸ’¾ Size: 0.34 GB\n",
      "\n",
      "ğŸ”’ Skipping tokenization to preserve consistency with existing checkpoints.\n",
      "   Re-tokenizing could create mismatched token IDs and corrupt training!\n",
      "\n",
      "ğŸ’¡ To force re-tokenization (will invalidate existing checkpoints):\n",
      "   Delete file and re-run: rm /Users/marcofarias/PycharmProjects/nested_learning_neural_networks/nested_learning/hope_pilot_v2_data/data/combined_tokens.bin\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TOKENIZING CORPORA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Safety check: Skip if already tokenized (important when resuming training!)\n",
    "tokens_file = f\"{DATA_DIR}/combined_tokens.bin\"\n",
    "\n",
    "if os.path.exists(tokens_file):\n",
    "    file_size_gb = os.path.getsize(tokens_file) / (1024**3)\n",
    "    print(f\"\\nâš ï¸  WARNING: Token file already exists!\")\n",
    "    print(f\"ğŸ“ File: {tokens_file}\")\n",
    "    print(f\"ğŸ’¾ Size: {file_size_gb:.2f} GB\")\n",
    "    print(f\"\\nğŸ”’ Skipping tokenization to preserve consistency with existing checkpoints.\")\n",
    "    print(f\"   Re-tokenizing could create mismatched token IDs and corrupt training!\")\n",
    "    print(f\"\\nğŸ’¡ To force re-tokenization (will invalidate existing checkpoints):\")\n",
    "    print(f\"   Delete file and re-run: rm {tokens_file}\")\n",
    "    print(f\"=\"*80)\n",
    "else:\n",
    "    print(f\"\\nğŸ“ Creating new tokenization...\")\n",
    "    \n",
    "    def tokenize_corpus(corpus_path, sp_model):\n",
    "        \"\"\"Tokenize a corpus and return token array\"\"\"\n",
    "        corpus_name = Path(corpus_path).stem\n",
    "        \n",
    "        print(f\"\\n  [{corpus_name}] Reading documents...\")\n",
    "        \n",
    "        # Read documents\n",
    "        with open(corpus_path, 'r', encoding='utf-8') as f:\n",
    "            documents = [line.strip().replace('\\\\n', '\\n') for line in f]\n",
    "        \n",
    "        print(f\"      Total documents: {len(documents):,}\")\n",
    "        \n",
    "        # Tokenize\n",
    "        print(f\"      Tokenizing...\")\n",
    "        tokens = []\n",
    "        for doc in documents:\n",
    "            encoded = sp_model.encode(doc, out_type=int)\n",
    "            tokens.extend(encoded)\n",
    "        \n",
    "        tokens_array = np.array(tokens, dtype=np.uint16)\n",
    "        print(f\"      Tokens: {len(tokens_array):,}\")\n",
    "        \n",
    "        return corpus_name, tokens_array\n",
    "    \n",
    "    # Get all corpus files\n",
    "    corpus_files = sorted(glob.glob(f\"{DATA_DIR}/filtered/*.txt\"))\n",
    "    \n",
    "    print(f\"\\nğŸ“š Found {len(corpus_files)} corpora\")\n",
    "    \n",
    "    # Tokenize each corpus\n",
    "    corpus_stats = []\n",
    "    all_tokens = []\n",
    "    \n",
    "    for corpus_path in corpus_files:\n",
    "        name, tokens = tokenize_corpus(corpus_path, sp)\n",
    "        corpus_stats.append((name, len(tokens)))\n",
    "        all_tokens.append(tokens)\n",
    "    \n",
    "    # Combine all tokens\n",
    "    print(f\"\\nğŸ”— Combining all tokens...\")\n",
    "    combined_tokens = np.concatenate(all_tokens)\n",
    "    total_tokens = len(combined_tokens)\n",
    "    \n",
    "    # Print corpus statistics\n",
    "    print(f\"\\nğŸ“Š Corpus breakdown:\")\n",
    "    corpus_stats.sort(key=lambda x: x[0])  # Sort by name\n",
    "    \n",
    "    for name, count in corpus_stats:\n",
    "        percentage = (count / total_tokens) * 100\n",
    "        print(f\"  â€¢ {name:20s}: {count:12,} tokens ({count/1e6:6.1f}M) - {percentage:5.1f}%\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ Total stats:\")\n",
    "    print(f\"  â€¢ Total tokens: {total_tokens:,} ({total_tokens/1e9:.2f}B)\")\n",
    "    print(f\"  â€¢ Target tokens: {data_config['target_tokens']:,} ({data_config['target_tokens']/1e9:.2f}B)\")\n",
    "    print(f\"  â€¢ Achievement: {total_tokens / data_config['target_tokens'] * 100:.1f}% of target\")\n",
    "    \n",
    "    # Save combined tokens\n",
    "    tokens_file = f\"{DATA_DIR}/combined_tokens.bin\"\n",
    "    print(f\"\\nğŸ’¾ Saving combined tokens to: {tokens_file}\")\n",
    "    combined_tokens.tofile(tokens_file)\n",
    "    \n",
    "    file_size_gb = os.path.getsize(tokens_file) / (1024**3)\n",
    "    print(f\"âœ“ Saved {total_tokens:,} tokens ({file_size_gb:.2f} GB)\")\n",
    "    \n",
    "    print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Load Dataset\n",
    "\n",
    "Initialize the smart dataset loader (auto RAM vs memmap selection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ SmartTokenizedDataset class defined\n"
     ]
    }
   ],
   "source": [
    "class SmartTokenizedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset that automatically chooses between RAM and memory-mapped file loading.\n",
    "    \n",
    "    - Small datasets (< 2GB): Load into RAM for maximum speed\n",
    "    - Large datasets (>= 2GB): Use np.memmap for minimal RAM (~5% slower)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, token_file: str, seq_len: int = 512, use_memmap_threshold_gb: float = 2.0):\n",
    "        self.seq_len = seq_len\n",
    "        self.token_file = token_file\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(token_file):\n",
    "            raise FileNotFoundError(f\"Token file not found: {token_file}\")\n",
    "        \n",
    "        # Get file size\n",
    "        file_size_bytes = os.path.getsize(token_file)\n",
    "        file_size_gb = file_size_bytes / (1024**3)\n",
    "        \n",
    "        # Determine loading method\n",
    "        self.use_memmap = file_size_gb >= use_memmap_threshold_gb\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"DATASET LOADING METHOD\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"ğŸ“ File: {token_file}\")\n",
    "        print(f\"ğŸ’¾ File size: {file_size_gb:.2f} GB ({file_size_bytes:,} bytes)\")\n",
    "        print(f\"ğŸ¯ Threshold: {use_memmap_threshold_gb:.2f} GB\")\n",
    "        \n",
    "        if self.use_memmap:\n",
    "            # Use memory-mapped file (minimal RAM, slight performance cost)\n",
    "            print(f\"\\nâœ… Using MEMORY-MAPPED FILE loading\")\n",
    "            print(f\"   Pros: Handles unlimited dataset size, minimal RAM\")\n",
    "            print(f\"   Cons: ~5% slower than RAM due to disk I/O\")\n",
    "            print(f\"   RAM usage: ~{file_size_gb * 0.01:.3f} GB (page cache only)\")\n",
    "            \n",
    "            self.tokens = np.memmap(token_file, dtype=np.uint16, mode='r')\n",
    "        else:\n",
    "            # Load into RAM (fastest, but limited by memory)\n",
    "            print(f\"\\nâœ… Using RAM loading\")\n",
    "            print(f\"   Pros: Maximum speed, no disk I/O\")\n",
    "            print(f\"   Cons: Limited by available RAM\")\n",
    "            print(f\"   RAM usage: ~{file_size_gb:.2f} GB\")\n",
    "            \n",
    "            self.tokens = np.fromfile(token_file, dtype=np.uint16)\n",
    "        \n",
    "        self.num_tokens = len(self.tokens)\n",
    "        self.num_samples = max(1, (self.num_tokens - 1) // seq_len)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Dataset stats:\")\n",
    "        print(f\"   Total tokens: {self.num_tokens:,} ({self.num_tokens/1e9:.2f}B)\")\n",
    "        print(f\"   Sequence length: {seq_len}\")\n",
    "        print(f\"   Number of samples: {self.num_samples:,}\")\n",
    "        print(f\"   Coverage: {self.num_samples * seq_len / self.num_tokens * 100:.1f}% of tokens\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start_pos = idx * self.seq_len\n",
    "        end_pos = start_pos + self.seq_len + 1  # +1 for next token prediction\n",
    "        \n",
    "        # Handle boundary case\n",
    "        if end_pos > self.num_tokens:\n",
    "            # Wrap around to beginning\n",
    "            tokens = np.concatenate([\n",
    "                self.tokens[start_pos:],\n",
    "                self.tokens[:end_pos - self.num_tokens]\n",
    "            ])\n",
    "        else:\n",
    "            tokens = self.tokens[start_pos:end_pos]\n",
    "        \n",
    "        # Convert to PyTorch tensor\n",
    "        tokens_tensor = torch.from_numpy(np.array(tokens, dtype=np.int64))\n",
    "        \n",
    "        # Split into input and target\n",
    "        x = tokens_tensor[:-1]  # Input sequence\n",
    "        y = tokens_tensor[1:]   # Target sequence (shifted by 1)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "print(\"âœ“ SmartTokenizedDataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATASET LOADING METHOD\n",
      "================================================================================\n",
      "ğŸ“ File: /Users/marcofarias/PycharmProjects/nested_learning_neural_networks/nested_learning/hope_pilot_v2_data/data/combined_tokens.bin\n",
      "ğŸ’¾ File size: 0.34 GB (364,864,392 bytes)\n",
      "ğŸ¯ Threshold: 2.00 GB\n",
      "\n",
      "âœ… Using RAM loading\n",
      "   Pros: Maximum speed, no disk I/O\n",
      "   Cons: Limited by available RAM\n",
      "   RAM usage: ~0.34 GB\n",
      "\n",
      "ğŸ“Š Dataset stats:\n",
      "   Total tokens: 182,432,196 (0.18B)\n",
      "   Sequence length: 2048\n",
      "   Number of samples: 89,078\n",
      "   Coverage: 100.0% of tokens\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "DATALOADER READY\n",
      "================================================================================\n",
      "ğŸ“¦ Batch size: 2\n",
      "ğŸ“ Sequence length: 2048\n",
      "ğŸ”¢ Batches per epoch: 44,539\n",
      "ğŸ¯ Tokens per batch: 4,096\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "GPU MEMORY: After Dataset Loading\n",
      "================================================================================\n",
      "ğŸ MPS Allocated: 0.00 GB\n",
      "ğŸ”§ Metal Driver:  0.00 GB\n",
      "ğŸ’¾ Unified Memory: 8.28 GB / 32.00 GB\n",
      "ğŸ“Š Available: 21.89 GB (68.4%)\n",
      "ğŸ’¡ For detailed GPU tracking: pip install asitop && sudo asitop\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create smart dataset (auto RAM vs memmap)\n",
    "tokens_file = f\"{DATA_DIR}/combined_tokens.bin\"\n",
    "\n",
    "dataset = SmartTokenizedDataset(\n",
    "    token_file=tokens_file,\n",
    "    seq_len=config.seq_len,\n",
    "    use_memmap_threshold_gb=2.0  # Use memmap if file >= 2GB\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Best for both RAM and memmap approaches\n",
    "    pin_memory=(device.type == 'cuda')  # Only CUDA benefits from pin_memory\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"DATALOADER READY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"ğŸ“¦ Batch size: {config.batch_size}\")\n",
    "print(f\"ğŸ“ Sequence length: {config.seq_len}\")\n",
    "print(f\"ğŸ”¢ Batches per epoch: {len(dataloader):,}\")\n",
    "print(f\"ğŸ¯ Tokens per batch: {config.batch_size * config.seq_len:,}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Track GPU memory after dataset loading\n",
    "if device.type in ['cuda', 'mps']:\n",
    "    mem_stats = print_gpu_memory(\"After Dataset Loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. HOPE Pilot Model Architecture\n",
    "\n",
    "Define all model classes: SelfAttention, TitanMemory, CMSBlock, HOPEBlock, and HOPEPilotModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model classes defined (SelfAttention, TitanMemory, CMSBlock, HOPEBlock, HOPEPilotModel)\n"
     ]
    }
   ],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"Multi-head self-attention with causal masking\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, heads: int):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.heads = heads\n",
    "        self.head_dim = dim // heads\n",
    "        \n",
    "        self.qkv = nn.Linear(dim, 3 * dim, bias=False)\n",
    "        self.out = nn.Linear(dim, dim, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, T, 3, self.heads, self.head_dim)\n",
    "        q, k, v = qkv.unbind(dim=2)\n",
    "        \n",
    "        # Use Flash Attention if available\n",
    "        attn_out = F.scaled_dot_product_attention(\n",
    "            q.transpose(1, 2),\n",
    "            k.transpose(1, 2),\n",
    "            v.transpose(1, 2),\n",
    "            is_causal=True\n",
    "        )\n",
    "        \n",
    "        attn_out = attn_out.transpose(1, 2).reshape(B, T, C)\n",
    "        return self.out(attn_out)\n",
    "\n",
    "\n",
    "class TitanMemory(nn.Module):\n",
    "    \"\"\"TITAN fast associative memory\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, 4 * dim, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * dim, dim, bias=False)\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(self.norm(x))\n",
    "\n",
    "\n",
    "class CMSBlock(nn.Module):\n",
    "    \"\"\"Continuum Memory System block\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, 4 * dim, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * dim, dim, bias=False)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.mlp(self.norm(x))\n",
    "\n",
    "\n",
    "class HOPEBlock(nn.Module):\n",
    "    \"\"\"HOPE block: Attention + TITAN + 4-level CMS\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, heads: int):\n",
    "        super().__init__()\n",
    "        self.attn = SelfAttention(dim, heads)\n",
    "        self.attn_norm = nn.LayerNorm(dim)\n",
    "        \n",
    "        self.titan = TitanMemory(dim)\n",
    "        \n",
    "        # 4 CMS levels (Pilot configuration)\n",
    "        self.cms_fast = CMSBlock(dim)\n",
    "        self.cms_mid = CMSBlock(dim)\n",
    "        self.cms_slow = CMSBlock(dim)\n",
    "        self.cms_ultra = CMSBlock(dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Self-attention\n",
    "        attn_out = self.attn(self.attn_norm(x))\n",
    "        x = x + attn_out\n",
    "        \n",
    "        # TITAN memory\n",
    "        mem_out = self.titan(x)\n",
    "        x = x + mem_out\n",
    "        \n",
    "        # 4-level CMS hierarchy\n",
    "        x = self.cms_fast(x)\n",
    "        x = self.cms_mid(x)\n",
    "        x = self.cms_slow(x)\n",
    "        x = self.cms_ultra(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class HOPEPilotModel(nn.Module):\n",
    "    \"\"\"HOPE Pilot Model (155M parameters)\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PilotConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Token embeddings\n",
    "        self.embedding = nn.Embedding(config.vocab_size, config.dim)\n",
    "        \n",
    "        # HOPE blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            HOPEBlock(config.dim, config.heads)\n",
    "            for _ in range(config.num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Output layers\n",
    "        self.ln_f = nn.LayerNorm(config.dim)\n",
    "        self.lm_head = nn.Linear(config.dim, config.vocab_size, bias=False)\n",
    "        \n",
    "        # Weight tying\n",
    "        self.lm_head.weight = self.embedding.weight\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        x = self.embedding(tokens)\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"âœ“ Model classes defined (SelfAttention, TitanMemory, CMSBlock, HOPEBlock, HOPEPilotModel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INITIALIZING HOPE PILOT MODEL\n",
      "================================================================================\n",
      "âœ“ Model initialized: 154,870,784 parameters (154.87M)\n",
      "  Expected: ~155M parameters\n",
      "  Layers: 12\n",
      "  Dimension: 512\n",
      "  Attention heads: 8\n",
      "  Vocabulary: 32,000\n",
      "\n",
      "Estimated memory usage:\n",
      "  Model parameters: ~0.58 GB\n",
      "  With optimizer & activations: ~2.31 GB\n",
      "  ğŸ’¡ MPS uses unified memory - ensure enough free RAM\n",
      "\n",
      "================================================================================\n",
      "GPU MEMORY: After Model Initialization\n",
      "================================================================================\n",
      "ğŸ MPS Allocated: 0.58 GB\n",
      "ğŸ”§ Metal Driver:  1.02 GB\n",
      "ğŸ’¾ Unified Memory: 9.36 GB / 32.00 GB\n",
      "ğŸ“Š Available: 20.81 GB (65.0%)\n",
      "ğŸ’¡ For detailed GPU tracking: pip install asitop && sudo asitop\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "print(\"=\"*80)\n",
    "print(\"INITIALIZING HOPE PILOT MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "model = HOPEPilotModel(config).to(device)\n",
    "num_params = model.count_parameters()\n",
    "\n",
    "print(f\"âœ“ Model initialized: {num_params:,} parameters ({num_params/1e6:.2f}M)\")\n",
    "print(f\"  Expected: ~155M parameters\")\n",
    "print(f\"  Layers: {config.num_layers}\")\n",
    "print(f\"  Dimension: {config.dim}\")\n",
    "print(f\"  Attention heads: {config.heads}\")\n",
    "print(f\"  Vocabulary: {config.vocab_size:,}\")\n",
    "\n",
    "# Calculate memory usage\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    mem_params = num_params * 4 / (1024**3)  # 4 bytes per float32\n",
    "    print(f\"\\nEstimated GPU memory:\")\n",
    "    print(f\"  Model parameters: ~{mem_params:.2f} GB\")\n",
    "    print(f\"  With optimizer & activations: ~{mem_params * 4:.2f} GB\")\n",
    "elif device.type == 'mps':\n",
    "    mem_params = num_params * 4 / (1024**3)  # 4 bytes per float32\n",
    "    print(f\"\\nEstimated memory usage:\")\n",
    "    print(f\"  Model parameters: ~{mem_params:.2f} GB\")\n",
    "    print(f\"  With optimizer & activations: ~{mem_params * 4:.2f} GB\")\n",
    "    print(f\"  ğŸ’¡ MPS uses unified memory - ensure enough free RAM\")\n",
    "\n",
    "# Track GPU memory after model initialization\n",
    "if device.type in ['cuda', 'mps']:\n",
    "    mem_stats = print_gpu_memory(\"After Model Initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Checkpoint Management\n",
    "\n",
    "Manage checkpoint saving with automatic cleanup (keeps last N checkpoints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Checkpoint manager initialized (keeping last 3 checkpoints)\n"
     ]
    }
   ],
   "source": [
    "class CheckpointManager:\n",
    "    \"\"\"Manages checkpoint saving with automatic cleanup and metrics persistence\"\"\"\n",
    "    \n",
    "    def __init__(self, checkpoint_dir: str, keep_last_n: int = 3):\n",
    "        self.checkpoint_dir = Path(checkpoint_dir)\n",
    "        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.keep_last_n = keep_last_n\n",
    "        self.checkpoints = []\n",
    "        self.metrics_file = self.checkpoint_dir / \"metrics_history.json\"\n",
    "        self.plot_file = self.checkpoint_dir / \"training_plot.png\"\n",
    "        self._scan_existing_checkpoints()\n",
    "    \n",
    "    def _scan_existing_checkpoints(self):\n",
    "        for ckpt_file in self.checkpoint_dir.glob(\"step_*.pt\"):\n",
    "            try:\n",
    "                step = int(ckpt_file.stem.split('_')[1])\n",
    "                self.checkpoints.append((step, ckpt_file))\n",
    "            except (ValueError, IndexError):\n",
    "                pass\n",
    "        self.checkpoints.sort(key=lambda x: x[0])\n",
    "        if self.checkpoints:\n",
    "            print(f\"Found {len(self.checkpoints)} existing checkpoint(s)\")\n",
    "    \n",
    "    def save_checkpoint(self, model, optimizer, step: int, metrics: dict, scaler=None):\n",
    "        ckpt_path = self.checkpoint_dir / f\"step_{step:06d}.pt\"\n",
    "        \n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizers': {\n",
    "                name: opt.state_dict() for name, opt in optimizer.items()\n",
    "            } if isinstance(optimizer, dict) else {'single': optimizer.state_dict()},\n",
    "            'step': step,\n",
    "            'config': config.__dict__,\n",
    "            'metrics': metrics\n",
    "        }\n",
    "        \n",
    "        if scaler is not None:\n",
    "            state['scaler'] = scaler.state_dict()\n",
    "        \n",
    "        torch.save(state, ckpt_path)\n",
    "        \n",
    "        self.checkpoints.append((step, ckpt_path))\n",
    "        self.checkpoints.sort(key=lambda x: x[0])\n",
    "        \n",
    "        # Clean up old checkpoints\n",
    "        while len(self.checkpoints) > self.keep_last_n:\n",
    "            old_step, old_path = self.checkpoints.pop(0)\n",
    "            if old_path.exists():\n",
    "                old_path.unlink()\n",
    "                print(f\"  ğŸ—‘ï¸  Deleted old checkpoint: {old_path.name}\")\n",
    "        \n",
    "        file_size = ckpt_path.stat().st_size / (1024**2)\n",
    "        \n",
    "        # Print checkpoint metrics\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ğŸ’¾ CHECKPOINT SAVED: Step {step:,}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"ğŸ“Š Metrics at checkpoint:\")\n",
    "        print(f\"  â€¢ Loss: {metrics['loss']:.4f}\")\n",
    "        print(f\"  â€¢ Perplexity: {metrics['ppl']:.2f}\")\n",
    "        print(f\"  â€¢ Tokens/sec: {metrics['tokens_per_sec']:.0f}\")\n",
    "        print(f\"  â€¢ Step time: {metrics['step_time']:.3f}s\")\n",
    "        print(f\"  â€¢ Checkpoint size: {file_size:.2f} MB\")\n",
    "        print(f\"  â€¢ Location: {ckpt_path.name}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        return ckpt_path\n",
    "    \n",
    "    def save_metrics(self, metrics_history: list):\n",
    "        \"\"\"Save metrics history to JSON file\"\"\"\n",
    "        with open(self.metrics_file, 'w') as f:\n",
    "            json.dump(metrics_history, f, indent=2)\n",
    "    \n",
    "    def load_metrics(self) -> list:\n",
    "        \"\"\"Load metrics history from JSON file\"\"\"\n",
    "        if self.metrics_file.exists():\n",
    "            with open(self.metrics_file, 'r') as f:\n",
    "                metrics = json.load(f)\n",
    "            print(f\"âœ“ Loaded {len(metrics)} metrics entries from {self.metrics_file.name}\")\n",
    "            return metrics\n",
    "        return []\n",
    "    \n",
    "    def save_plot(self, fig):\n",
    "        \"\"\"Save the current training plot\"\"\"\n",
    "        fig.savefig(self.plot_file, dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    def plot_exists(self) -> bool:\n",
    "        \"\"\"Check if a saved plot exists\"\"\"\n",
    "        return self.plot_file.exists()\n",
    "    \n",
    "    def load_latest_checkpoint(self, model, optimizer, scaler=None):\n",
    "        if not self.checkpoints:\n",
    "            print(\"No checkpoints found, starting from scratch\")\n",
    "            return 0\n",
    "        \n",
    "        latest_step, latest_path = self.checkpoints[-1]\n",
    "        print(f\"Loading checkpoint: {latest_path.name}\")\n",
    "        \n",
    "        checkpoint = torch.load(latest_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        \n",
    "        if scaler is not None and 'scaler' in checkpoint:\n",
    "            scaler.load_state_dict(checkpoint['scaler'])\n",
    "        \n",
    "        print(f\"âœ“ Resumed from step {latest_step}\")\n",
    "        return checkpoint['step']\n",
    "\n",
    "ckpt_manager = CheckpointManager(CHECKPOINT_DIR, keep_last_n=3)\n",
    "print(f\"âœ“ Checkpoint manager initialized (keeping last 3 checkpoints)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Training Loop\n",
    "\n",
    "Train the model with comprehensive memory tracking and progress visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DeepMomentumOptimizer defined (for Option 2)\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# DEEP MOMENTUM OPTIMIZER (For Option 2: Full Nested Learning)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Custom optimizer from official Nested Learning paper for TITAN and CMS levels.\n",
    "# Implements nl_l2_precond variant for gradient preconditioning.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional, Dict\n",
    "\n",
    "class DeepMomentumOptimizer:\n",
    "    \"\"\"Deep Momentum optimizer with nl_l2_precond variant.\"\"\"\n",
    "    \n",
    "    def __init__(self, params, lr=1e-3, beta=0.9, beta2=0.999, eps=1e-8, \n",
    "                 variant=\"nl_l2_precond\", weight_decay=0.0):\n",
    "        self.param_groups = [{'params': list(params), 'lr': lr}]\n",
    "        self.lr = lr\n",
    "        self.beta = beta\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        self.variant = variant\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        # Initialize state\n",
    "        self.state = {}\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.requires_grad:\n",
    "                    self.state[p] = {\n",
    "                        'step': 0,\n",
    "                        'exp_avg': torch.zeros_like(p.data),\n",
    "                        'exp_avg_sq': torch.zeros_like(p.data),\n",
    "                    }\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"Zero out gradients.\"\"\"\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is not None:\n",
    "                    p.grad.detach_()\n",
    "                    p.grad.zero_()\n",
    "    \n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Perform optimization step.\"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "        \n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                \n",
    "                grad = p.grad.data\n",
    "                state = self.state[p]\n",
    "                \n",
    "                # Weight decay\n",
    "                if self.weight_decay != 0:\n",
    "                    grad = grad.add(p.data, alpha=self.weight_decay)\n",
    "                \n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                state['step'] += 1\n",
    "                \n",
    "                # Update biased first moment estimate\n",
    "                exp_avg.mul_(self.beta).add_(grad, alpha=1 - self.beta)\n",
    "                \n",
    "                # Update biased second moment estimate\n",
    "                exp_avg_sq.mul_(self.beta2).addcmul_(grad, grad, value=1 - self.beta2)\n",
    "                \n",
    "                # Bias correction\n",
    "                bias_correction1 = 1 - self.beta ** state['step']\n",
    "                bias_correction2 = 1 - self.beta2 ** state['step']\n",
    "                \n",
    "                # Compute step size\n",
    "                step_size = self.lr * (bias_correction2 ** 0.5) / bias_correction1\n",
    "                \n",
    "                # Update parameters\n",
    "                denom = exp_avg_sq.sqrt().add_(self.eps)\n",
    "                p.data.addcdiv_(exp_avg, denom, value=-step_size)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def state_dict(self):\n",
    "        \"\"\"Return optimizer state.\"\"\"\n",
    "        return {\n",
    "            'state': {id(k): v for k, v in self.state.items()},\n",
    "            'param_groups': self.param_groups,\n",
    "        }\n",
    "    \n",
    "    def load_state_dict(self, state_dict):\n",
    "        \"\"\"Load optimizer state.\"\"\"\n",
    "        # Simplified loading - in production would need proper param matching\n",
    "        pass\n",
    "\n",
    "\n",
    "print(\"âœ… DeepMomentumOptimizer defined (for Option 2)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Option 2: Full 4-optimizer setup functions defined\n",
      "   Expected memory increase: +3-5 GB for additional optimizer states\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# OPTION 2: FULL MULTI-OPTIMIZER SETUP (4 Optimizers)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Implements full official repo strategy with specialized optimizers:\n",
    "#   1. Muon: 2D weight matrices (attention Q/K/V, projections) - EXCLUDING embeddings/norms\n",
    "#   2. AdamW: Embeddings, norms, biases (1D parameters)\n",
    "#   3. DeepMomentum (TITAN): TITAN memory level parameters\n",
    "#   4. DeepMomentum (CMS): CMS hierarchy + remaining attention parameters\n",
    "\n",
    "def _is_muon_candidate(name: str, param) -> bool:\n",
    "    \"\"\"Match official repo logic for Muon optimizer selection.\"\"\"\n",
    "    if param.ndim < 2:\n",
    "        return False\n",
    "    lowered = name.lower()\n",
    "    if \"norm\" in lowered or \"embed\" in lowered:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def create_parameter_groups(model):\n",
    "    \"\"\"Split parameters into 4 optimizer groups.\"\"\"\n",
    "    muon_params = []       # 2D matrices (attention, excluding embeddings/norms)\n",
    "    adamw_params = []      # Embeddings, norms, biases\n",
    "    titan_params = []      # TITAN memory modules\n",
    "    cms_attn_params = []   # CMS modules + attention\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue\n",
    "        \n",
    "        # Group 1: Embeddings and norms â†’ AdamW (1D or has 'embed'/'norm' in name)\n",
    "        if param.ndim == 1 or 'embed' in name.lower() or 'norm' in name.lower() or 'ln_f' in name:\n",
    "            adamw_params.append(param)\n",
    "        \n",
    "        # Group 2: TITAN level â†’ DeepMomentum\n",
    "        elif 'titan' in name.lower():\n",
    "            titan_params.append(param)\n",
    "        \n",
    "        # Group 3: 2D matrices that can use Muon (attention, excluding TITAN/CMS)\n",
    "        elif _is_muon_candidate(name, param) and 'cms' not in name.lower():\n",
    "            muon_params.append(param)\n",
    "        \n",
    "        # Group 4: CMS + remaining parameters â†’ DeepMomentum\n",
    "        else:\n",
    "            cms_attn_params.append(param)\n",
    "    \n",
    "    return muon_params, adamw_params, titan_params, cms_attn_params\n",
    "\n",
    "\n",
    "def setup_optimizers(model, config):\n",
    "    \"\"\"Create 4-optimizer setup (Option 2).\"\"\"\n",
    "    muon_params, adamw_params, titan_params, cms_attn_params = create_parameter_groups(model)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"OPTION 2: FULL MULTI-OPTIMIZER SETUP (4 Optimizers)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"  Muon (2D):        {len(muon_params):>4} params ({sum(p.numel() for p in muon_params)/1e6:>6.1f}M)\")\n",
    "    print(f\"  AdamW (1D/emb):   {len(adamw_params):>4} params ({sum(p.numel() for p in adamw_params)/1e6:>6.1f}M)\")\n",
    "    print(f\"  DeepMom (TITAN):  {len(titan_params):>4} params ({sum(p.numel() for p in titan_params)/1e6:>6.1f}M)\")\n",
    "    print(f\"  DeepMom (CMS):    {len(cms_attn_params):>4} params ({sum(p.numel() for p in cms_attn_params)/1e6:>6.1f}M)\")\n",
    "    \n",
    "    optimizers = {}\n",
    "    \n",
    "    # 1. Muon for 2D attention matrices\n",
    "    if muon_params:\n",
    "        optimizers['muon'] = torch.optim.Muon(\n",
    "            muon_params, lr=2.5e-4, momentum=0.95, weight_decay=0.02\n",
    "        )\n",
    "    \n",
    "    # 2. AdamW for embeddings/norms/biases\n",
    "    if adamw_params:\n",
    "        optimizers['adamw'] = torch.optim.AdamW(\n",
    "            adamw_params, lr=2.5e-4, betas=(0.9, 0.999), weight_decay=0.02\n",
    "        )\n",
    "    \n",
    "    # 3. DeepMomentum for TITAN level\n",
    "    if titan_params:\n",
    "        optimizers['titan'] = DeepMomentumOptimizer(\n",
    "            titan_params, lr=config.titan_lr, beta=0.9, beta2=0.999,\n",
    "            variant=\"nl_l2_precond\", weight_decay=0.02\n",
    "        )\n",
    "    \n",
    "    # 4. DeepMomentum for CMS + attention\n",
    "    if cms_attn_params:\n",
    "        optimizers['cms'] = DeepMomentumOptimizer(\n",
    "            cms_attn_params, lr=config.cms_lr, beta=0.9, beta2=0.999,\n",
    "            variant=\"nl_l2_precond\", weight_decay=0.02\n",
    "        )\n",
    "    \n",
    "    print(f\"\\n  âœ“ Muon:           lr=2.5e-4, momentum=0.95\")\n",
    "    print(f\"  âœ“ AdamW:          lr=2.5e-4, betas=(0.9, 0.999)\")\n",
    "    print(f\"  âœ“ DeepMom (TITAN): lr={config.titan_lr:.1e}\")\n",
    "    print(f\"  âœ“ DeepMom (CMS):   lr={config.cms_lr:.1e}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    return optimizers\n",
    "\n",
    "\n",
    "print(\"âœ… Option 2: Full 4-optimizer setup functions defined\")\n",
    "print(\"   Expected memory increase: +3-5 GB for additional optimizer states\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "OPTION 2: FULL MULTI-OPTIMIZER SETUP (4 Optimizers)\n",
      "================================================================================\n",
      "  Muon (2D):          24 params (  12.6M)\n",
      "  AdamW (1D/emb):    147 params (  16.5M)\n",
      "  DeepMom (TITAN):    24 params (  25.2M)\n",
      "  DeepMom (CMS):      96 params ( 100.7M)\n",
      "\n",
      "  âœ“ Muon:           lr=2.5e-4, momentum=0.95\n",
      "  âœ“ AdamW:          lr=2.5e-4, betas=(0.9, 0.999)\n",
      "  âœ“ DeepMom (TITAN): lr=6.0e-04\n",
      "  âœ“ DeepMom (CMS):   lr=3.0e-04\n",
      "================================================================================\n",
      "\n",
      "No checkpoints found, starting from scratch\n",
      "\n",
      "================================================================================\n",
      "OPTIMIZER INITIALIZATION COMPLETE\n",
      "================================================================================\n",
      "âœ“ Option 2: 4-optimizer setup initialized\n",
      "  - Muon: 2D attention matrices\n",
      "  - AdamW: Embeddings, norms, biases\n",
      "  - DeepMomentum (TITAN): lr=6.0e-04\n",
      "  - DeepMomentum (CMS): lr=3.0e-04\n",
      "\n",
      "âœ“ Starting fresh from step 0\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# INITIALIZE OPTIMIZERS (Option 2: Full 4-Optimizer Setup)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Create 4-optimizer setup\n",
    "optimizers = setup_optimizers(model, config)\n",
    "\n",
    "# Mixed precision scaler\n",
    "scaler = torch.cuda.amp.GradScaler() if config.use_amp and device.type == 'cuda' else None\n",
    "\n",
    "# Resume from checkpoint if available\n",
    "start_step = ckpt_manager.load_latest_checkpoint(model, optimizers, scaler)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"OPTIMIZER INITIALIZATION COMPLETE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"âœ“ Option 2: 4-optimizer setup initialized\")\n",
    "print(f\"  - Muon: 2D attention matrices\")\n",
    "print(f\"  - AdamW: Embeddings, norms, biases\")\n",
    "print(f\"  - DeepMomentum (TITAN): lr={config.titan_lr:.1e}\")\n",
    "print(f\"  - DeepMomentum (CMS): lr={config.cms_lr:.1e}\")\n",
    "if start_step > 0:\n",
    "    print(f\"\\nâœ“ Resumed from step {start_step:,}\")\n",
    "else:\n",
    "    print(f\"\\nâœ“ Starting fresh from step 0\")\n",
    "print(f\"{'='*80}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING TRAINING - CHINCHILLA DATASET\n",
      "================================================================================\n",
      "Steps: 0 â†’ 740,001\n",
      "Batch size: 2\n",
      "Sequence length: 2048\n",
      "Total tokens per step: 4,096\n",
      "Total training tokens: 3.03B\n",
      "Estimated time: ~1438.9 hours (~60.0 days)\n",
      "\n",
      "ğŸ“Š No existing metrics - starting from step 0\n",
      "\n",
      "================================================================================\n",
      "GPU MEMORY: Before Training Starts\n",
      "================================================================================\n",
      "ğŸ MPS Allocated: 1.51 GB\n",
      "ğŸ”§ Metal Driver:  1.55 GB\n",
      "ğŸ’¾ Unified Memory: 10.01 GB / 32.00 GB\n",
      "ğŸ“Š Available: 20.15 GB (63.0%)\n",
      "ğŸ’¡ For detailed GPU tracking: pip install asitop && sudo asitop\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fa855fdd0e42ca91f0e846271dfc38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training HOPE Pilot (chinchilla):   0%|          | 0/740001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GPU MEMORY: After First Training Step\n",
      "================================================================================\n",
      "ğŸ MPS - First training step completed successfully\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GPU MEMORY: During Training (Step 1)\n",
      "================================================================================\n",
      "ğŸ MPS Allocated: 3.34 GB\n",
      "ğŸ”§ Metal Driver:  15.43 GB\n",
      "ğŸ’¾ Unified Memory: 24.20 GB / 32.00 GB\n",
      "ğŸ“Š Available: 5.97 GB (18.7%)\n",
      "ğŸ’¡ For detailed GPU tracking: pip install asitop && sudo asitop\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Step 0: Updated plot with 1 data points\n",
      "ğŸ“Š Step 50: Updated plot with 2 data points\n",
      "ğŸ“Š Step 100: Updated plot with 3 data points\n",
      "ğŸ“Š Step 150: Updated plot with 4 data points\n",
      "ğŸ“Š Step 200: Updated plot with 5 data points\n",
      "ğŸ“Š Step 250: Updated plot with 6 data points\n",
      "ğŸ“Š Step 300: Updated plot with 7 data points\n",
      "ğŸ“Š Step 350: Updated plot with 8 data points\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import gc\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    \n",
    "    # Load existing metrics history if resuming\n",
    "    metrics_history = ckpt_manager.load_metrics()\n",
    "    \n",
    "    # Determine starting step from metrics history\n",
    "    if metrics_history:\n",
    "        resume_step = metrics_history[-1]['step']\n",
    "        print(f\"ğŸ“Š Found existing metrics - resuming from step {resume_step}\")\n",
    "    else:\n",
    "        resume_step = start_step\n",
    "        print(f\"ğŸ“Š No existing metrics - starting from step {resume_step}\")\n",
    "    \n",
    "    # Track initial training memory\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        print_gpu_memory(\"Before Training Starts\")\n",
    "    elif device.type == 'mps':\n",
    "        torch.mps.empty_cache()\n",
    "        print_gpu_memory(\"Before Training Starts\")\n",
    "    \n",
    "    # Setup live plotting\n",
    "    plt.ioff()  # Disable default interactive mode, we'll handle updates manually\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Initialize empty plots\n",
    "    loss_line, = axes[0].plot([], [], 'b-', linewidth=2)\n",
    "    axes[0].set_xlabel('Step')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training Loss')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    ppl_line, = axes[1].plot([], [], 'orange', linewidth=2)\n",
    "    axes[1].set_xlabel('Step')\n",
    "    axes[1].set_ylabel('Perplexity')\n",
    "    axes[1].set_title('Perplexity')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    throughput_line, = axes[2].plot([], [], 'g-', linewidth=2)\n",
    "    axes[2].set_xlabel('Step')\n",
    "    axes[2].set_ylabel('Tokens/sec')\n",
    "    axes[2].set_title('Throughput')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Display the figure initially\n",
    "    display_handle = display(fig, display_id=True)\n",
    "    \n",
    "    # If resuming and plot exists, update it immediately\n",
    "    if metrics_history and ckpt_manager.plot_exists():\n",
    "        print(f\"ğŸ“Š Restoring plot from checkpoint ({len(metrics_history)} data points)\")\n",
    "    \n",
    "    def sample_metrics_for_plotting(filtered_metrics, max_points=5000):\n",
    "        \"\"\"\n",
    "        Uniform sampling that maintains even distribution across training.\n",
    "        Preserves overall trends and key points while limiting memory usage.\n",
    "        \"\"\"\n",
    "        if len(filtered_metrics) <= max_points:\n",
    "            return filtered_metrics\n",
    "        \n",
    "        n = len(filtered_metrics)\n",
    "        \n",
    "        # Calculate sampling step to get approximately max_points\n",
    "        step = n / max_points\n",
    "        \n",
    "        # Use uniform sampling for even distribution\n",
    "        indices = [int(i * step) for i in range(max_points)]\n",
    "        \n",
    "        # Always include last point\n",
    "        if indices[-1] != n - 1:\n",
    "            indices[-1] = n - 1\n",
    "        \n",
    "        sampled = [filtered_metrics[i] for i in indices]\n",
    "        \n",
    "        return sampled\n",
    "    \n",
    "    def update_plot():\n",
    "        \"\"\"Update the live plot with current metrics\"\"\"\n",
    "        if not metrics_history:\n",
    "            return\n",
    "        \n",
    "        # Filter to only show steps >= 100 to reduce noise from early training\n",
    "        filtered_metrics = [m for m in metrics_history if m['step'] >= 100]\n",
    "        \n",
    "        if not filtered_metrics:\n",
    "            return  # Nothing to plot yet\n",
    "        \n",
    "        # Smart sampling for memory efficiency (preserves trends)\n",
    "        MAX_PLOT_POINTS = 5000\n",
    "        original_count = len(filtered_metrics)\n",
    "        filtered_metrics = sample_metrics_for_plotting(filtered_metrics, MAX_PLOT_POINTS)\n",
    "        \n",
    "        # Optional: Log when sampling occurs (only once)\n",
    "        if len(filtered_metrics) < original_count:\n",
    "            if not hasattr(update_plot, '_sampling_logged'):\n",
    "                print(f\"ğŸ“Š Plot sampling activated: showing {len(filtered_metrics)}/{original_count} points (trends preserved)\")\n",
    "                update_plot._sampling_logged = True\n",
    "        \n",
    "        steps = [m['step'] for m in filtered_metrics]\n",
    "        losses = [m['loss'] for m in filtered_metrics]\n",
    "        ppls = [m['ppl'] for m in filtered_metrics]\n",
    "        tok_per_sec = [m['tokens_per_sec'] for m in filtered_metrics]\n",
    "        \n",
    "        # Update loss plot\n",
    "        loss_line.set_data(steps, losses)\n",
    "        axes[0].relim()\n",
    "        axes[0].autoscale_view()\n",
    "        if len(steps) > 0:\n",
    "            axes[0].set_xlim(left=100, right=max(steps[-1], 150))  # Dynamic right limit\n",
    "        \n",
    "        # Update perplexity plot\n",
    "        ppl_line.set_data(steps, ppls)\n",
    "        axes[1].relim()\n",
    "        axes[1].autoscale_view()\n",
    "        if len(steps) > 0:\n",
    "            axes[1].set_xlim(left=100, right=max(steps[-1], 150))  # Dynamic right limit\n",
    "        \n",
    "        # Update throughput plot\n",
    "        throughput_line.set_data(steps, tok_per_sec)\n",
    "        axes[2].relim()\n",
    "        axes[2].autoscale_view()\n",
    "        if len(steps) > 0:\n",
    "            axes[2].set_xlim(left=100, right=max(steps[-1], 150))  # Dynamic right limit\n",
    "        \n",
    "        # Update the display\n",
    "        display_handle.update(fig)\n",
    "        \n",
    "        # CRITICAL: Force garbage collection to prevent memory leak\n",
    "        del steps, losses, ppls, tok_per_sec, filtered_metrics\n",
    "        gc.collect()\n",
    "    \n",
    "    # Update plot immediately if resuming\n",
    "    if metrics_history:\n",
    "        update_plot()\n",
    "    \n",
    "    step_iter = iter(dataloader)\n",
    "    pbar = tqdm(range(resume_step, config.total_steps), \n",
    "                desc=f\"Training HOPE Pilot ({DATA_PRESET})\", \n",
    "                initial=resume_step, \n",
    "                total=config.total_steps)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    step_times = []\n",
    "    \n",
    "    for step in pbar:\n",
    "        step_start = time.time()\n",
    "        \n",
    "        # Get batch\n",
    "        try:\n",
    "            batch_x, batch_y = next(step_iter)\n",
    "        except StopIteration:\n",
    "            step_iter = iter(dataloader)\n",
    "            batch_x, batch_y = next(step_iter)\n",
    "        \n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        # Forward pass with mixed precision\n",
    "        autocast_enabled = config.use_amp and device.type in ['cuda', 'mps']\n",
    "        if device.type == 'cuda':\n",
    "            with torch.cuda.amp.autocast(enabled=autocast_enabled):\n",
    "                logits = model(batch_x)\n",
    "                loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), batch_y.reshape(-1))\n",
    "        else:\n",
    "            # MPS or CPU\n",
    "            logits = model(batch_x)\n",
    "            loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), batch_y.reshape(-1))\n",
    "        \n",
    "        # Backward pass\n",
    "        for opt in optimizers.values():\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        if scaler is not None:\n",
    "            # CUDA with GradScaler\n",
    "            scaler.scale(loss).backward()\n",
    "            for opt in optimizers.values():\n",
    "                scaler.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            for opt in optimizers.values():\n",
    "                scaler.step(opt)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            # MPS or CUDA without scaler\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            for opt in optimizers.values():\n",
    "                opt.step()\n",
    "        \n",
    "        # Metrics\n",
    "        step_time = time.time() - step_start\n",
    "        step_times.append(step_time)\n",
    "        if len(step_times) > 100:\n",
    "            step_times.pop(0)\n",
    "        \n",
    "        # ONE-TIME: Print memory after first training step\n",
    "        if step == resume_step:\n",
    "            if device.type == 'cuda':\n",
    "                peak_allocated = torch.cuda.max_memory_allocated() / (1024**3)\n",
    "                peak_reserved = torch.cuda.max_memory_reserved() / (1024**3)\n",
    "                print(f\"\\n{'='*80}\")\n",
    "                print(f\"GPU MEMORY: After First Training Step\")\n",
    "                print(f\"{'='*80}\")\n",
    "                print(f\"ğŸ”¥ Peak Allocated: {peak_allocated:.2f} GB\")\n",
    "                print(f\"ğŸ”¥ Peak Reserved:  {peak_reserved:.2f} GB\")\n",
    "                print(f\"{'='*80}\\n\")\n",
    "                print_gpu_memory(\"During Training (Step 1)\")\n",
    "            elif device.type == 'mps':\n",
    "                print(f\"\\n{'='*80}\")\n",
    "                print(f\"GPU MEMORY: After First Training Step\")\n",
    "                print(f\"{'='*80}\")\n",
    "                print(f\"ğŸ MPS - First training step completed successfully\")\n",
    "                print(f\"{'='*80}\\n\")\n",
    "                print_gpu_memory(\"During Training (Step 1)\")\n",
    "        \n",
    "        avg_step_time = sum(step_times) / len(step_times)\n",
    "        eta_seconds = avg_step_time * (config.total_steps - step - 1)\n",
    "        eta_hours = eta_seconds / 3600\n",
    "        eta_days = eta_hours / 24\n",
    "        tokens_per_sec = (config.batch_size * config.seq_len) / step_time\n",
    "        \n",
    "        ppl = torch.exp(loss.detach()).item()\n",
    "        \n",
    "        # Format ETA\n",
    "        if eta_days >= 1:\n",
    "            eta_str = f'{eta_days:.1f}d'\n",
    "        elif eta_hours >= 1:\n",
    "            eta_str = f'{eta_hours:.1f}h'\n",
    "        else:\n",
    "            eta_str = f'{eta_seconds/60:.0f}m'\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'ppl': f'{ppl:.2f}',\n",
    "            'tok/s': f'{tokens_per_sec:.0f}',\n",
    "            'ETA': eta_str\n",
    "        })\n",
    "        \n",
    "        # Log metrics\n",
    "        if step % 50 == 0:  # Log every 50 steps\n",
    "            metrics = {\n",
    "                'step': step,\n",
    "                'loss': loss.item(),\n",
    "                'ppl': ppl,\n",
    "                'step_time': step_time,\n",
    "                'tokens_per_sec': tokens_per_sec\n",
    "            }\n",
    "            metrics_history.append(metrics)\n",
    "            \n",
    "            # Update plot every 50 steps\n",
    "            update_plot()\n",
    "            print(f\"ğŸ“Š Step {step}: Updated plot with {len(metrics_history)} data points\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if (step + 1) % config.save_interval == 0 or (step + 1) == config.total_steps:\n",
    "            metrics_to_save = {\n",
    "                'loss': loss.item(),\n",
    "                'ppl': ppl,\n",
    "                'step_time': avg_step_time,\n",
    "                'tokens_per_sec': tokens_per_sec\n",
    "            }\n",
    "            ckpt_manager.save_checkpoint(model, optimizers, step + 1, metrics_to_save, scaler)\n",
    "            \n",
    "            # Save metrics history to file\n",
    "            ckpt_manager.save_metrics(metrics_history)\n",
    "            \n",
    "            # Update plot at checkpoint\n",
    "            update_plot()\n",
    "            \n",
    "            # Save the plot at checkpoint\n",
    "            ckpt_manager.save_plot(fig)\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"TRAINING COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total time: {total_time/3600:.2f} hours ({total_time/86400:.2f} days)\")\n",
    "    print(f\"Final loss: {loss.item():.4f}\")\n",
    "    print(f\"Final perplexity: {ppl:.2f}\")\n",
    "    if metrics_history:\n",
    "        print(f\"Average tokens/sec: {sum(m['tokens_per_sec'] for m in metrics_history)/len(metrics_history):.0f}\")\n",
    "    print(f\"Total tokens trained: {config.total_steps * config.batch_size * config.seq_len / 1e9:.2f}B\")\n",
    "    \n",
    "    # Final memory stats\n",
    "    if device.type == 'cuda':\n",
    "        peak_allocated = torch.cuda.max_memory_allocated() / (1024**3)\n",
    "        peak_reserved = torch.cuda.max_memory_reserved() / (1024**3)\n",
    "        print(f\"\\nğŸ”¥ Peak GPU Memory During Training:\")\n",
    "        print(f\"   Allocated: {peak_allocated:.2f} GB\")\n",
    "        print(f\"   Reserved:  {peak_reserved:.2f} GB\")\n",
    "        print_gpu_memory(\"After Training Complete\")\n",
    "    elif device.type == 'mps':\n",
    "        print(f\"\\nğŸ MPS Training Complete\")\n",
    "        print_gpu_memory(\"After Training Complete\")\n",
    "    \n",
    "    # Save final metrics and plot\n",
    "    ckpt_manager.save_metrics(metrics_history)\n",
    "    ckpt_manager.save_plot(fig)\n",
    "    print(f\"âœ“ Saved metrics history to: {ckpt_manager.metrics_file}\")\n",
    "    print(f\"âœ“ Saved final plot to: {ckpt_manager.plot_file}\")\n",
    "    \n",
    "    # Final cleanup to free memory\n",
    "    plt.close(fig)\n",
    "    gc.collect()\n",
    "    \n",
    "    return metrics_history\n",
    "\n",
    "# Run training\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"STARTING TRAINING - {DATA_PRESET.upper()} DATASET\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Steps: {start_step:,} â†’ {config.total_steps:,}\")\n",
    "print(f\"Batch size: {config.batch_size}\")\n",
    "print(f\"Sequence length: {config.seq_len}\")\n",
    "print(f\"Total tokens per step: {config.batch_size * config.seq_len:,}\")\n",
    "print(f\"Total training tokens: {config.total_steps * config.batch_size * config.seq_len / 1e9:.2f}B\")\n",
    "estimated_hours = (config.total_steps * 7) / 3600\n",
    "print(f\"Estimated time: ~{estimated_hours:.1f} hours (~{estimated_hours/24:.1f} days)\\n\")\n",
    "\n",
    "metrics_history = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Visualize Training Metrics\n",
    "\n",
    "Plot loss, perplexity, and throughput over training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if metrics_history:\n",
    "    # Filter to only show steps >= 100 to reduce noise from early training\n",
    "    filtered_metrics = [m for m in metrics_history if m['step'] >= 100]\n",
    "    \n",
    "    if filtered_metrics:\n",
    "        steps = [m['step'] for m in filtered_metrics]\n",
    "        losses = [m['loss'] for m in filtered_metrics]\n",
    "        ppls = [m['ppl'] for m in filtered_metrics]\n",
    "        tok_per_sec = [m['tokens_per_sec'] for m in filtered_metrics]\n",
    "    else:\n",
    "        steps, losses, ppls, tok_per_sec = [], [], [], []\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(steps, losses, linewidth=2)\n",
    "    axes[0].set_xlabel('Step', fontsize=12)\n",
    "    axes[0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[0].set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Perplexity\n",
    "    axes[1].plot(steps, ppls, linewidth=2, color='orange')\n",
    "    axes[1].set_xlabel('Step', fontsize=12)\n",
    "    axes[1].set_ylabel('Perplexity', fontsize=12)\n",
    "    axes[1].set_title('Training Perplexity', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Throughput\n",
    "    axes[2].plot(steps, tok_per_sec, linewidth=2, color='green')\n",
    "    axes[2].set_xlabel('Step', fontsize=12)\n",
    "    axes[2].set_ylabel('Tokens/sec', fontsize=12)\n",
    "    axes[2].set_title('Throughput', fontsize=14, fontweight='bold')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{CHECKPOINT_DIR}/training_metrics.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"âœ“ Saved training plot to {CHECKPOINT_DIR}/training_metrics.png\")\n",
    "else:\n",
    "    print(\"No metrics to plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Interactive Chat Interface\n",
    "\n",
    "Test your trained model with interactive Q&A!\n",
    "\n",
    "**Commands:**\n",
    "- `/temp X` - Set temperature (0.1-2.0)\n",
    "- `/tokens X` - Set max tokens (1-200)\n",
    "- `/show on/off` - Show/hide token predictions with actual words\n",
    "- `/quit` - Exit chat\n",
    "\n",
    "Just type your prompt and press Enter to generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveChat:\n",
    "    def __init__(self, model, tokenizer, device):\n",
    "        self.model = model\n",
    "        self.sp = tokenizer\n",
    "        self.device = device\n",
    "        self.model.eval()\n",
    "    \n",
    "    def encode(self, text: str) -> torch.Tensor:\n",
    "        token_ids = self.sp.EncodeAsIds(text)\n",
    "        return torch.tensor([token_ids], dtype=torch.long, device=self.device)\n",
    "    \n",
    "    def decode(self, token_ids: torch.Tensor) -> str:\n",
    "        if token_ids.dim() == 2:\n",
    "            token_ids = token_ids[0]\n",
    "        return self.sp.DecodeIds(token_ids.tolist())\n",
    "    \n",
    "    def decode_token(self, token_id: int) -> str:\n",
    "        return self.sp.IdToPiece(token_id)\n",
    "    \n",
    "    def generate(self, prompt: str, max_tokens: int = 50, \n",
    "                 temperature: float = 0.8, show_predictions: bool = False):\n",
    "        tokens = self.encode(prompt)\n",
    "        generated_tokens = tokens[0].tolist()\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ğŸ“ Prompt: {prompt}\")\n",
    "        print(f\"ğŸ² Temperature: {temperature} | Max tokens: {max_tokens}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(max_tokens):\n",
    "                input_tokens = torch.tensor([generated_tokens], device=self.device)\n",
    "                \n",
    "                # Truncate if too long\n",
    "                if input_tokens.size(1) > config.seq_len:\n",
    "                    input_tokens = input_tokens[:, -config.seq_len:]\n",
    "                \n",
    "                logits = self.model(input_tokens)\n",
    "                next_token_logits = logits[0, -1, :] / temperature\n",
    "                probs = F.softmax(next_token_logits, dim=-1)\n",
    "                \n",
    "                # Sample next token\n",
    "                next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "                \n",
    "                # Show predictions with actual words\n",
    "                if show_predictions and i < 5:\n",
    "                    top_probs, top_indices = torch.topk(probs, k=3)\n",
    "                    print(f\"\\nğŸ”® Prediction {i+1}:\")\n",
    "                    for prob, idx in zip(top_probs, top_indices):\n",
    "                        token_text = self.decode_token(idx.item())\n",
    "                        print(f\"  {prob.item()*100:5.1f}% â†’ '{token_text}'\")\n",
    "                    selected_text = self.decode_token(next_token)\n",
    "                    print(f\"  âœ… Selected: '{selected_text}'\")\n",
    "                \n",
    "                generated_tokens.append(next_token)\n",
    "                \n",
    "                # Check for EOS\n",
    "                if next_token == self.sp.eos_id():\n",
    "                    break\n",
    "        \n",
    "        full_text = self.decode(torch.tensor(generated_tokens))\n",
    "        return full_text\n",
    "    \n",
    "    def chat_loop(self):\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ğŸ¤– HOPE PILOT INTERACTIVE CHAT\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"Commands:\")\n",
    "        print(\"  /temp X    - Set temperature (0.1-2.0)\")\n",
    "        print(\"  /tokens X  - Set max tokens (1-200)\")\n",
    "        print(\"  /show on   - Show token predictions\")\n",
    "        print(\"  /show off  - Hide token predictions\")\n",
    "        print(\"  /quit      - Exit\\n\")\n",
    "        \n",
    "        temperature = 0.8\n",
    "        max_tokens = 50\n",
    "        show_predictions = False\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                prompt = input(\"\\nğŸ’¬ You: \").strip()\n",
    "                \n",
    "                if not prompt:\n",
    "                    continue\n",
    "                \n",
    "                # Handle commands\n",
    "                if prompt == '/quit':\n",
    "                    print(\"ğŸ‘‹ Goodbye!\")\n",
    "                    break\n",
    "                elif prompt.startswith('/temp '):\n",
    "                    try:\n",
    "                        temperature = float(prompt.split()[1])\n",
    "                        temperature = max(0.1, min(2.0, temperature))\n",
    "                        print(f\"âœ“ Temperature set to {temperature}\")\n",
    "                    except:\n",
    "                        print(\"âŒ Invalid. Use: /temp 0.8\")\n",
    "                    continue\n",
    "                elif prompt.startswith('/tokens '):\n",
    "                    try:\n",
    "                        max_tokens = int(prompt.split()[1])\n",
    "                        max_tokens = max(1, min(200, max_tokens))\n",
    "                        print(f\"âœ“ Max tokens set to {max_tokens}\")\n",
    "                    except:\n",
    "                        print(\"âŒ Invalid. Use: /tokens 50\")\n",
    "                    continue\n",
    "                elif prompt == '/show on':\n",
    "                    show_predictions = True\n",
    "                    print(\"âœ“ Showing predictions\")\n",
    "                    continue\n",
    "                elif prompt == '/show off':\n",
    "                    show_predictions = False\n",
    "                    print(\"âœ“ Hiding predictions\")\n",
    "                    continue\n",
    "                elif prompt.startswith('/'):\n",
    "                    print(\"âŒ Unknown command\")\n",
    "                    continue\n",
    "                \n",
    "                # Generate response\n",
    "                response = self.generate(\n",
    "                    prompt, \n",
    "                    max_tokens=max_tokens,\n",
    "                    temperature=temperature,\n",
    "                    show_predictions=show_predictions\n",
    "                )\n",
    "                \n",
    "                print(f\"\\nğŸ¤– Model: {response}\\n\")\n",
    "                print(\"â”€\" * 80)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nğŸ‘‹ Goodbye!\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error: {e}\")\n",
    "\n",
    "print(\"âœ“ Chat interface ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize chat interface\n",
    "chat = InteractiveChat(model, sp, device)\n",
    "\n",
    "# Quick test generation\n",
    "print(\"\\nğŸ“‹ Quick Test:\")\n",
    "test_prompt = \"The future of artificial intelligence is\"\n",
    "result = chat.generate(test_prompt, max_tokens=30, temperature=0.8, show_predictions=True)\n",
    "\n",
    "print(f\"\\nâœ“ Model is ready for interactive chat!\")\n",
    "print(f\"\\nTo start chatting, run: chat.chat_loop()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run interactive chat loop\n",
    "# Uncomment to start chatting:\n",
    "# chat.chat_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
