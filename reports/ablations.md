# Planned Ablations ‚Äì Pilot Run

This document tracks the ablation studies we intend to run once the 3‚ÄØB-token pilot checkpoint is available. The goal is to isolate the contributions of teach-signal scaling, CMS chunk accumulation, self-modifiers, and optimizer choices (AdamW vs Muon) before moving to larger configs.

## 1. Teach-signal schedule
| Variant | Description | Status | Notes |
|---------|-------------|--------|-------|
| Baseline | Warmup 2‚ÄØk ‚Üí decay 120‚ÄØk‚Üí140‚ÄØk (current pilot config) | ‚è≥ | Use pilot checkpoint |
| No decay | Warmup only, no decay | ‚è≥ | Expect higher plasticity, risk of instability |
| Per-level scale | Different teach_scale per CMS level | ‚è≥ | Requires config changes |

## 2. CMS chunk accumulation
| Variant | Description | Status | Notes |
|---------|-------------|--------|-------|
| Full CMS | Chunk accumulation + telemetry (default) | ‚úÖ smoke-tested | Verified via `tests/test_cms.py` |
| No chunking | Update each token (Transformer-like) | ‚è≥ | Compare long-context recall |
| Sparse chunks | Update every 512 tokens only | ‚è≥ | Stress long-term retention |

## 3. Self-modifier toggles
| Variant | Description | Status |
|---------|-------------|--------|
| Enabled | SelfModifier active (default) | ‚è≥ pilot |
| Disabled | Freeze self-modifier params | ‚è≥ |
| Teach-only | Teach signal applied but self-mod not updated | ‚è≥ |

## 4. Optimizer swaps
| Variant | Description | Status |
|---------|-------------|--------|
| AdamW fused | `optim.type=adamw` with fused kernels (default) | ‚úÖ smoke-tested |
| Muon hybrid | `optim.type=muon` for ‚â•2D params, AdamW for embeddings/bias | ‚è≥ pilot |
| Full Muon | Force Muon everywhere | ‚è≥ (needs stability check) |

## 5. Automation hooks
| Tool | Purpose | Status | Notes |
|------|---------|--------|-------|
| `scripts/package_pilot_release.sh` | Copies latest pilot checkpoint/config/logs into `artifacts/pilot_release/` and updates metadata | ‚úÖ | Use after every significant checkpoint (e.g., 1k-step milestones) so collaborators can download a coherent bundle. |
| `scripts/eval/run_pilot_suite.sh` | Runs zero-shot, NIAH (up to 64k), and continual harnesses (plus optional TITAN baseline) with memorization flags enabled | ‚úÖ | Set `HOPE_CHECKPOINT`, `TITAN_*`, etc., to reuse for each ablation. Outputs land under `eval/`. |

## 5. Evaluation checklist per ablation
1. Run zero-shot suite (`scripts/eval/zeroshot.py --tasks all --memorize ...`).
2. Run extended NIAH (`--context-lengths 2048 --context-lengths 4096 --context-lengths 8192 --context-lengths 16384 --context-lengths 32768 --context-lengths 65536`).
3. Run continual-learning harness with memorization toggles (`--memorize --memorize-steps 2 --memorize-no-reset` and baseline run without memorization).
4. Record metrics in `artifacts/pilot_release/` (JSON/CSV) and summarize deltas here.

_Status legend:_ ‚úÖ complete, ‚è≥ pending, üîÑ running, ‚ö†Ô∏è blocked.

## 6. Reference snapshot ‚Äì Pilot step 600 (HOPE)
| Eval | Command | Output | Notes |
|------|---------|--------|-------|
| Zero-shot (PIQA, 32 samples, memorize on) | `scripts/eval/zeroshot.py --config configs/pilot.yaml --checkpoint artifacts/pilot_release/checkpoint.pt --tasks piqa --max-samples 32 --memorize --memorize-steps 2 --memorize-use-correct-answer` | `eval/zeroshot_pilot.json` ‚Üí accuracy **0.5625** | Matches smoke baseline; ready baseline for future ablations. |
| NIAH (2k/4k contexts, 1 sample each) | `scripts/eval/niah.py ... --context-lengths 2048 --context-lengths 4096 --samples-per-length 1` | `eval/niah_pilot.json` ‚Üí both accuracies **0.0** | As expected this early; use as reference once longer contexts show gains. |
| Continual (sample segments, 1 batch each) | `scripts/eval/continual.py ... --batch-size 2 --max-batches 1` | `eval/continual_pilot.json` ‚Üí per-segment CE ‚âà 39‚Äì43 | Provides initial forgetting baseline before running CMS/self-mod ablations. |

All outputs are copied to `artifacts/pilot_release/` via `scripts/package_pilot_release.sh` for reproducibility.
